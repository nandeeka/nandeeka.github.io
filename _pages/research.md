---
layout: default
title: Research
permalink: /research/
---

I am broadly interested in new abstractions for improving the design and
implementation of efficient kernels for tensor algebra and related domains. My
work spans both theory---through methodologies for designing efficient
kernels---and practice---by applying these methodologies to propose efficient
implementations for specific kernels.

Here is my [CV](../cv/) and my [Google Scholar](https://scholar.google.com/citations?user=xcJ7Nq8AAAAJ&hl=en).

## Publications

**Nandeeka Nayak**, Xinrui Wu, Toluwanimi O. Odemuyiwa, Michael
Pellauer, Joel S. Emer, and Christopher W. Fletcher. "From TeAAL to FuseMax:
Separation of Concerns for Attention Accelerator Design".  IEEE Micro 2025.
[[paper](https://ieeexplore.ieee.org/document/11082638)]

**Nandeeka Nayak**, Xinrui Wu, Toluwanimi O. Odemuyiwa, Michael Pellauer, Joel
S. Emer, and Christopher W. Fletcher. "FuseMax: Leveraging Extended Einsums to
Optimize Attention Accelerator Design".  MICRO 2024.
[[paper](https://arxiv.org/abs/2406.10491)]
[[artifact](https://github.com/FPSG-UIUC/micro24-fusemax-artifact)]
<br />
<span style="color:red">IEEE Micro Top Picks 2025 Winner</span>

**Nandeeka Nayak**, Toluwanimi O. Odemuyiwa, Shubham Ugare, Christopher W.
Fletcher, Michael Pellauer, and Joel S. Emer. "TeAAL: A Declarative Framework
for Modeling Sparse Tensor Accelerators". MICRO 2023.
[[paper](https://arxiv.org/abs/2304.07931)]
[[artifact](https://github.com/FPSG-UIUC/micro23-teaal-artifact)]
[[compiler](https://github.com/FPSG-UIUC/teaal-compiler)]
<br />
<span style="color:red">IEEE Micro Top Picks 2024 Honorable Mention</span>

Jose Rodrigo Sanchez Vicarte, Pradyumna Shome, **Nandeeka Nayak**, Caroline
Trippel, Adam Morrison, David Kohlbrenner, and Christopher W. Fletcher.
"Opening Pandora’s Box: A Systematic Study of New Ways Microarchitecture Can
Leak Private Data". ISCA 2021.
[[paper](https://dl.acm.org/doi/abs/10.1109/ISCA52012.2021.00035)]
[[artifact](https://github.com/FPSG-UIUC/Pandora)]
<br />
<span style="color:red">Intel Hardware Security Academic Award 2022
Honorable Mention</span>

**Nandeeka Nayak**, Makoto Nara, Timmy Gambin, Zoë Wood, and Christopher M.
Clark.  "Machine learning techniques for auv side-scan sonar data feature
extraction as applied to intelligent search for underwater archaeological
sites". FSR 2019.
[[paper](https://link.springer.com/chapter/10.1007/978-981-15-9460-1_16)]

## Tutorials
*TeAAL and HiFiber: Precise and Concise Descriptions of (Sparse) Tensor Algebra
Accelerators*. Co-located with MICRO 2025.
[[website](https://teaal.csail.mit.edu/tutorials/2025.micro-teaal/index.html)]
[[artifact](https://github.com/FPSG-UIUC/accelerator-zoo)]


*TeAAL and HiFiber: Precise and Concise Descriptions of (Sparse) Tensor Algebra
Accelerators*. Co-located with MICRO 2024.
[[website](https://teaal.csail.mit.edu/tutorials/2024.micro-teaal/index.html)]
[[artifact](https://github.com/FPSG-UIUC/accelerator-zoo)]
[[slides](https://drive.google.com/drive/u/1/folders/1qiVS_To4Hd8-Uy8edjzwRf8esai2lZcr)]

## Talks/Posters

*A Structured Methodology for Implementing Efficient Tensor Algebra Kernels*.
Seminar at Yale University 2025.

*FuseMax: Leveraging Extended Einsums to Optimize Attention Accelerator
Design*. MLArchSys 2024.
[[program](https://sites.google.com/view/mlarchsys/isca-2024/schedule)]
[[paper](https://openreview.net/pdf?id=HKwsTuKEpo)]

*TeAAL: A Declarative Framework for Modeling Sparse Tensor Accelerators*.
Highlights of Parallel Computing 2024.
[[program](https://ucrparlay.github.io/hopc24/papers/)]
[[paper](https://dl.acm.org/doi/10.1145/3670684.3673418)]

*Extended Einsums: Domain-Specific Kernels in the Language of Tensor Algebra*.
Stanford AHA Seminar 2024.

*TeAAL: A Declarative Framework for Modeling Sparse Tensor Accelerators*.
Workshop on Sparse Tensor Computations 2023.
[[program](https://solomonik.cs.illinois.edu/tensor_workshop/index.html)]
[[talk](https://www.youtube.com/watch?v=BSis3h_A51Y)]


*TeAAL: A Declarative Framework for Modeling Sparse Tensor Accelerators*.
CTSTA 2023. [[program](https://pldi23.sigplan.org/home/ctsta-2023)]

*TeAAL: A Declarative Framework for Modeling Sparse Tensor Accelerators*.
DRAGSTERS 2023. [[program](https://pldi23.sigplan.org/home/dragsters-2023)]
